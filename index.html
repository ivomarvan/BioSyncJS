<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gesture Recognition</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
        }
        video {
            display: block;
            width: 320px;
            height: 240px;
            border: 2px solid #ccc;
            margin-bottom: 10px;
        }
        .output {
            font-size: 2rem;
            margin-top: 10px;
        }
        .fps {
            margin-top: 5px;
            font-size: 1rem;
            color: #666;
        }
        .gestures-menu {
            font-size: 1.5rem;
        }
    </style>
</head>
<body>
<p>Choose on from: <span class="gestures-menu">ğŸ‘ğŸ‘âœŒï¸â˜ï¸ âœŠ ğŸ¤Ÿ</span></p>
    <video id="video" autoplay></video>
    <div class="output" id="output">ğŸ¤·</div>
    <div class="fps" id="fps">FPS: 0</div>

    <script type="module">
        import {
            GestureRecognizer,
            FilesetResolver
        } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

        let videoElement = document.getElementById('video');
        let outputElement = document.getElementById('output');
        let fpsElement = document.getElementById('fps');
        let lastFrameTime = performance.now();
        let frameCount = 0;

        const gestures = {
            'Thumb_Up': 'ğŸ‘',
            'Thumb_Down': 'ğŸ‘',
            'Victory': 'âœŒï¸',
            'Pointing_Up': 'â˜ï¸',
            'Closed_Fist': 'âœŠ',
            'ILoveYou': 'ğŸ¤Ÿ',
            'Open_Palm': 'ğŸ–ï¸',
        };

        function updateFPS() {
            const currentTime = performance.now();
            const deltaTime = currentTime - lastFrameTime;
            frameCount++;
            if (deltaTime >= 1000) {
                const fps = Math.round((frameCount / deltaTime) * 1000);
                fpsElement.textContent = `FPS: ${fps}`;
                frameCount = 0;
                lastFrameTime = currentTime;
            }
        }

        let gestureRecognizer;
        let runningMode = 'VIDEO';

        async function setupGestureRecognizer() {
            const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
            gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
                    delegate: "GPU"
                },
                runningMode: runningMode
            });

            startVideo();
        }

        function startVideo() {
            navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                videoElement.srcObject = stream;
                videoElement.addEventListener("loadeddata", predictWebcam);
            });
        }

        async function predictWebcam() {
            if (!gestureRecognizer) {
                return;
            }

            const nowInMs = Date.now();
            const results = await gestureRecognizer.recognizeForVideo(videoElement, nowInMs);


            updateFPS();

            if (results.gestures && results.gestures.length > 0) {
                const gesture = results.gestures[0][0].categoryName;
                console.log(results.gestures[0][0].categoryName);
                outputElement.textContent = gestures[gesture] || 'ğŸ¤·';
            }

            window.requestAnimationFrame(predictWebcam);
        }

        setupGestureRecognizer();
    </script>
</body>
</html>
